{
  "title": "CalibRead: Unobtrusive Eye Tracking Calibration from Natural Reading Behavior",
  "duration": "May 2023 ‑ February 2024",
  "author_list": [
    {"Chang Liu": "#1D67CD"},
    {"Chun Yu*": "#000000"},
    {"Xiangyang Wang": "#000000"},
    {"Jianxiao Jiang": "#000000"},
    {"Tianao Yang": "#000000"},
    {"Bingda Tang":  "#000000"},
    {"Yingtian Shi":  "#000000"},
    {"Chen Liang": "#000000"},
    {"Yuanchun Shi": "#000000"}
  ],
  "full_text": [
    {"image": "project-calibread_image_1.jpg", "description": "Image 1: (1) User reads texts naturally. (2) An unobservable “ground truth” exists for eye movements during reading, known only to the user themselves. (3) The output from the uncalibrated eye-tracking device exhibits misalignment with this ground truth. (4) Our model predicts reading behavior by identifying areas of the text where the user is likely to focus or ignore. (5) We apply a transformation to the uncalibrated data to minimize the discrepancy between it and the behavior predicted by our model. (6) The optimal transformation yields the calibrated eye movement data.\n\n"},
    {"paragraph": "In this paper, we present a novel, unobtrusive calibration method that leverages the association between eye-movement and text to calibrate eye-tracking devices during natural reading. The calibration process involves an iterative sequence of 3 steps: (1) matching the points of eye-tracking data with the text grids and boundary grids, (2) computing the weight for each point pair, and (3) optimizing the calibration parameters that best align point pairs through gradient descent. During this process, we assume that, from a holistic perspective, the gaze will cover the text area, effectively filling it after sufficient reading. Meanwhile, on a granular level, the gaze duration is influenced by the semantic and positional features of the text. Therefore, factors such as the presence of empty space, the positional features of tokens, and the depth of constituency parsing play important roles in calibration. Our method achieves accuracy error comparable to traditional 7-point mehtod after naturally reading 3 texts, which takes about 51.75 seconds. Moreover, we analyse the impact of different holistic and granular features on the calibration results.\n\n"},
    {"image": "project-calibread_image_2.png", "description": "Image 2: Overlay of all eye movement traces shows distinguishable rows, indicating eye movement during reading is strongly correlated with text in rows.\n\n"},
    {"image": "project-calibread_image_3.png", "description": "Image 3: Calibration Workflow. (a) Point Matching: We match each gaze point with its closet text grid center and boundary grid center. (b) Computing Weights: For each point pair, we calculate its weight. For text grids, the weight is computed using gaze density and gaze duration prediction. For text grids of punctuation and boundary grids, we set their weight to contants.(c) Gradient Descent: We compute the optimal affine matrix by minimizing the weighted distance between point pairs. After transforming the gaze points with affine matrix, we return to point matching to initiate the next iteration.\n\n"},
    {"iframe": "https://www.youtube.com/embed/hk2uDbdLJls?si=TWNn88AMwQMflqiL", "description": "Video of CalibRead (IMWUT 2024)"}
  ],
  "publication": {"description": "IMWUT 2024", "link": "https://dl.acm.org/doi/10.1145/3699737"},
  "cover": "project-calibread_cover.png"
}

